\documentclass[12pt]{article}
%\documentstyle[12pt,epsf]{article}
%\input epsf
%\usepackage{epsf}
% A useful Journal macro
\def\Journal#1#2#3#4{{#1} {\bf #2}, #3 (#4)}

% Some useful journal names
\def\NCA{\em Nuovo Cimento}
\def\NIM{\em Nucl. Instrum. Methods}
\def\NIMA{{\em Nucl. Instrum. Methods} A}
\def\NPB{{\em Nucl. Phys.} B}
\def\NP{{\em Nucl. Phys.} }
\def\PLB{{\em Phys. Lett.}  B}
\def\PL{{\em Phys. Lett.} }
\def\PRL{\em Phys. Rev. Lett.}
\def\PRD{{\em Phys. Rev.} D}
\def\PR{{\em Phys. Rev.} }
\def\ZPC{{\em Z. Phys.} C}


\begin{document}

\title{Review of the analysis note 2007-117 \\Upper Limit for the Photoproduction Cross Section
for the $\Phi^
{--}$(1862) Pentaquark State in
$\Xi^-\pi^-$ Decay Channel Using EG3 Data}

\author{Valery Kubarovsky\\
Jefferson Lab}
\date{January 08, 2010}
\maketitle

\section*{General Remarks}

The analysis note 2007-117 dated on December 16, 2009 is significantly improved in comparison with the note
dated on November 11, 2007. 

\begin{itemize}
\item{}
The Introduction was rewritten with the explanation of the basic physics, mass estimates, production cross sections and branching ratios. It gives the reader the relatively nice description of the main goals of the experiment.
\item{}
Data selection procedures and particle ID are described in more details. Especially I like how the authors made particle ID based on the selection of $\Lambda(1115)$ ground state.The improvement of the plot of
$\beta$ versus momentum of negative particles is very impressive (Fig. 5). 
\item{}
The extensive eg3 trigger inefficiency study was one of the major effort of the group. As a result the upper limit
was changed from 200 pb to 550 pb in comparison with the first reported upper limit at 2007.
\item{}
The check of the absolute normalization of the cross section upper limit was done using the
reaction $\gamma d \to \Delta^{++} \pi^- n$. The good agreement between eg3 cross section and g11-SAPHIR
cross sections gives the confidence that there are no big uncertainties in the reported upper limit.
\item{}
The use of different methods for the upper limit determination makes sure that the upper limit was evaluated correctly.
\item{}
Extensive checks of the possible systematics uncertainties was performed. The final result is stable under the variations of the major experimental cuts. The different MC production models gave the possibility to evaluate the
uncertainty in the determination of the upper limit. It is the largest systematic error in the analysis and it is as large as 20\%.  It is very nice result taking into account the high luminosity of the experiment and the difficulty with the trigger inefficiency.
\end{itemize}


\section*{Abstract}
I did not find the $\Lambda\pi^-\pi^-$ mass spectrum in the note. All figures include the cut
on the invariant mass $\Lambda\pi^-$ around $\Xi(1321)$ mass. Please correct me if I am wrong.
However in the abstract it is explicitly written that the invariant masses of the $\Lambda\pi^-\pi^-$
and $\Xi\pi^-$ were used in the analysis to set limits on the strength of narrow resonant structure near the mass
$M=1.86$ GeV. 

It is not clear what does it mean : to set limits on the strength of the narrow resonance? 

\section*{Introduction}
All particles in the anti-decuplet have spin=1/2 (including $\Xi^{--})$ , not 3/2 as it is pointed out in the Introduction.
It doesn't necessary mean of course that pentaquarks have J=1/2, but anti-decuplet particles have J=1/2.

\section*{Identification of $\Lambda(1116)$, page 9}
How did you define the timing cut boundaries in Fig. 4 (black curves)?

\section*{Identification of negative pions, page 11}
It is very smart to use the $\pi^-$ vertex time to select the RF bunch due to the large number of hits in tagger.
The fig. 5 is very impressive.
How did you define the boundaries for $\pi^-$ selection in Fig. 5.

How did you define the boundaries for $\pi^-$ selection in Fig. 15 (page 26)

\section*{Energy Los Correction, page 11}

..particle MAY lose part of the energy..
Particles always lose the energy due to the ionization. 
The Landau distribution has the minimum energy value and never equals zero.

Fig. 6. Do you have scatter plot of the $p\pi^-$ invariant mass as a function of proton momentum? 
of pion momentum?

\section*{Momentum correction, page 12}
This question is from our previous list of questions.
Could you please provide the supporting pictures and formulas for the momentum corrections?
Especially interesting how did you study the drift chambers misalignment?
I believe that you did everything correctly, however it will be nice to have it in the analysis note.

\section*{Selection of $\Xi(1321)$ events}
Fig. 7.  Does $c\tau$ value for $\Lambda$ consistent with the table value? 

Fig. 8.  Does $c\tau$ value for $\Xi$ consistent with the table value?

Did you take into account that $\Lambda$ and $\Xi$ decays may be out of the start counters coverage?
You need to check that the events satisfy your trigger conditions in your MC analysis.

Fig.9. Could you show the same distributions without $c\tau$ cut?

\section*{Fiducial and energy cuts}
Page 20.

Timing window 0.8 ns could be too narrow for the event's selection.
This cut has to be investigated in details to make sure that
there is no hidden loss. I remember from the g11 analysis that
you need to apply about 20\% correction factor if you want to use such s strong cut.

In your reply to our questions you wrote that the software timing window was changed to $\pm$3.2 ns. However in the analysis note you state that it is 0.8 ns.

\section*{Simulation}

Fig. 13. The comparison between simulated and real data are very useful from my point of view.
However it may be instructive to present the one-dimensional projections as well to stress the difference between
phase space generator and real data. As I see the MC momenta are harder than in the data.
it is not clear as well what $\pi^-$ is it? We have 3 $\pi^-$s in the reaction.

\section*{Model Dependence}
Fig. 17

What is the bump in the region of 1.55 GeV?

This figure is dramatically differed from the Fig. 11 of the old analysis note dated November 11, 2007.
The figure's capture is the same. What's up?

What model did you use for your final upper limit? 


\section*{Normalization}

Could you please provide the plots to check the photon flux normalization:
\begin{itemize}
\item{} Yield of your $\Lambda$ skim  as a function of the tagger EID? 
\item{}  Photon flux as a function of the tagger EID? 
\item{}  Yield of the $\Lambda$ skim normalized to the photon flux as a function of the tagger EID? 
\end{itemize}

\section*{Trigger inefficiencies}
Could you please zoom Fig. 21. It is difficult to understand who is who at this picture.

What were the trigger rates for trigger bit 5 and trigger bit 6 with and without prescale?

Fig.20. It is impossible to identify the run number on x-axis. Please mark run number by arrow
when the trigger was changed.

The statement that a trigger inefficiency is associated with the start counter presence in the trigger is not correct. The start counters were always in the trigger. The coincidence of MOR and OR of start counters was added only in the asynchronous  input of the trigger supervisor. 

The start counters HV was decreased in comparison with the g11 HV setting. It may create the trigger inefficiency if the SC amplitudes became closer to the discriminator threshold. However in this case the trigger 5 will be affected as well. 

There is interesting operator log entry 18483:\\
-------------------------------------------------------------------------------\\
Running trk\_mon on some cooked file, we noticed that sector 1 has a lot more tracks than it's fare share. After examining the trigger file Sergey found out that only the combinations with sector1 dot 3-sector trigger were included for trig bit 6. That makes (5x4)/(1x2) combinations out of (6x5x4)/(1x2x3) combinations, which is factor of 2 less. After loading the new fixed trigger file from Serguey the bit 6 increasing from by \~1.8 . 

-------------------------------------------------------------------------------\\
The log entry has run number 45512. Where is this point in the figure 20?

\begin{table}[h]
\begin{center}
\begin{tabular}{|c|c|c|} \hline
Pulse Width& Trigger Rate STxMOR (trigger bit 6)& MOR only (trigger bit 5) \\
\hline \hline
20 ns & 3.53 kHz & 4.10 kHz \\
15 ns & 3.07 kHz & 3.73 kHz \\
10 ns& 2.08 kHz  & 3.27 kHz\\

\hline
\end{tabular}
\end{center}
\caption {LogBook entry 18499. Run Number 45543. I=30 nA}
\label{tab:trstudy}
\end{table}


------------------------------------------------------------------------------\\
This is  the extraction from the operator logbook 18499.\\
The run number in this log is 45543.\\

Six different configurations were tested with current I=30 nA.



The delay curves MOR-Start counters are in Log book 
10 ns looks good. We decided to take test run with 10 ns, 
and stay with 15 ns. with Start counters in ASYNC. 

-------------------------------------------------------------------------------\\

The conclusion from the logbook:

However the ratio With\_Start\_counter\_in\_ASYNC/MOR only (2.08/3.27 for 10 ns) 
was not understood. Start counters enter into L1 trigger any way. 
There is a possibility that we have dead time in OR of all start counters. 
From this point of view it is more save to have MOR only and work with width=10 ns. The rate will be 3.27 kHz what is acceptable for DAQ.

My guess is that when we returned back to the configuration with ASYNC the pulse width of the MOR and Start Counter discriminators was set to 10 ns. It is clear from the table that this is not correct. I did not find in the log book when this trigger configuration was implemented (probably in January).  It is the main reason for the trigger inefficiency from my point of view.  

\section*{Invariant mass spectrum}

Fig. 23. The picture 23a and 23b are swapped.

Fig. 24. Could you please indicate the bin size. What is your mass resolution?

Fig. 26. Could you please indicate the bin size.

\section*{Upper Limits}

Page 44, line 3 from the bottom of the page.
What is $\xi^2$-distribution?

 
\section*{Conclusion}

You present theoretical estimations of the $\Xi^{--}$ cross section in the Introduction. 
The theoretical value for the photoproduction off neutron is in the range 0.4--1.5 nb. 
The conclusion is the right place to compare the experimental upper limit and 
theoretical expectation for the cross section and probably discuss this comparison. 



\newpage
\section*{ Normalization study of the EG3 data using the $\Delta^{++} $ reaction channel. \\
Analysis note 2009-106}

Page 1. Line 5 from bottom. radiator thickness is 5x10$^{-4}$ R.L.

Page 9. Line 10.   Misprint enrgy.  energy

Figure 5. What is right bottom plot? Could you please make a log scale?
Your generator uses the constant independent on beam energy t-slope. Is it really the case?
Usually the t-slope changes with beam energy. It may affect the acceptance calculations.

Figure 7. What is the left plot at this picture?

Figure 8. I don't see 2 ns structure on this plot. It is not clear from the text how did you get it?

Figure 9. What is your definition of vertex time?

Figure 11. The fit looks very strange. Did you really use the fit parameters to extract the acceptance?
I am not sure that you need to fit this distribution at all. Just take the number of the events in the histogram, and that's all.

Figure 12. You state that the flux uncertainty is not more that 2\%. The bottom plot shows however that the
flux is so irregular that it is hard to believe that the accuracy is really 2\%. Look for example to the
region EID=0-100, or peak in the region EID=180 or so. What is it? Can you prove that you measure the photon flux with 2\% accuracy? Weighted with the photon flux yield of your events may help to resolve this question.
    
There is big difference between figure 15 and figure 16 for the data with trigger bit 5. 
In figure 15 with 4 tracks and 3 sector events there is no drop in the normalized yield.
The distribution is almost flat. I found no reasonable explanation for this phenomena.

\section*{$\Delta^{++}$ cross section}

g11 group used the following correction in the data analysis:

\begin{itemize}
\item Rate dependence for the 3 prongs events - 19\%
\item  Multiple hits in the tagger   			          - 18\%
\item Trigger inefficiency                     			- 15\%
\item 2  ns tagger cut                   			  -  6\%
\end{itemize}

Do you have multiple hits corrections (2 or more tagger hits in the time window +/- 2 ns)?

Do you have 2 ns tagger cut correction in your analysis? 6\% of good events have tagger-CLAS time difference more than 2 ns.

\end{document}
